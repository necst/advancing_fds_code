{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10063dff-0068-4367-bf22-9bdc6e750c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467342f0-8b7f-4b2d-86e4-59b5954e22a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../results/experiment_1/trained_models.csv\"\n",
    "loss_file_name = \"../results/experiment_1/losses.csv\"\n",
    "df = pd.read_csv(file_name, index_col=0)\n",
    "models = ['logistic_regression_lt_is', 'neural_network_lt_is',\n",
    "       'random_forest_lt_is', 'support_vector_machine_lt_is', 'xgboost_lt_is',\n",
    "       'logistic_regression_lt_th', 'neural_network_lt_th',\n",
    "       'random_forest_lt_th', 'support_vector_machine_lt_th', 'xgboost_lt_th',\n",
    "       'logistic_regression_sf_is', 'neural_network_sf_is',\n",
    "       'random_forest_sf_is', 'support_vector_machine_sf_is', 'xgboost_sf_is',\n",
    "       'logistic_regression_sf_th', 'neural_network_sf_th',\n",
    "       'random_forest_sf_th', 'support_vector_machine_sf_th', 'xgboost_sf_th',\n",
    "       'logistic_regression_st_is', 'neural_network_st_is',\n",
    "       'random_forest_st_is', 'support_vector_machine_st_is', 'xgboost_st_is',\n",
    "       'logistic_regression_st_th', 'neural_network_st_th',\n",
    "       'random_forest_st_th', 'support_vector_machine_st_th', 'xgboost_st_th']\n",
    "models = sorted(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b727f-13ec-427a-9dfd-c4f67e018254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c10(amount):\n",
    "    return float(amount)\n",
    "\n",
    "def c01():\n",
    "    return 100.0\n",
    "\n",
    "def single_loss(true_label, predicted_label, amount):\n",
    "    assert((predicted_label) == 0 or predicted_label==1), print(predicted_label)\n",
    "    if abs(true_label - predicted_label)<1e-6:\n",
    "        return 0.0\n",
    "    if true_label == 1:\n",
    "        return c10(amount)\n",
    "    return c01()\n",
    "\n",
    "def f_losses(true_label, predictions, weights, amount, sogliazza=False):\n",
    "    l = []\n",
    "    for p in predictions:\n",
    "        l.append(single_loss(true_label, p, amount))\n",
    "    if not sogliazza:\n",
    "        l.append(np.sum(weights*l))\n",
    "    else:\n",
    "        w_pred = np.sum(predictions*weights)\n",
    "        l.append(single_loss(true_label, w_pred>0.5, amount))\n",
    "    return l\n",
    "\n",
    "def grad_loss(true_label, predictions, amount):\n",
    "    return (c01()*(1-true_label)-c10(amount)*true_label)*predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292818fa-929b-47c0-8399-2f7e1d26d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MWU:\n",
    "    def __init__(self, eta, n):\n",
    "        self.w = np.ones(n)/n\n",
    "        self.eta = eta\n",
    "        self.cumLoss = np.zeros(n)\n",
    "    \n",
    "    def predict(self, predictions):\n",
    "        return np.sum(self.w*predictions)\n",
    "    \n",
    "    def update(self, grad_loss):\n",
    "        self.cumLoss += grad_loss\n",
    "        if self.eta>=10:\n",
    "            i = np.argmax(-self.cumLoss)\n",
    "            self.w = np.zeros_like(self.w)\n",
    "            self.w[i] = 0\n",
    "        else:\n",
    "            self.w = self.w*np.exp(-self.eta*grad_loss)\n",
    "            self.w /= np.sum(self.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45929f41-164d-44c9-941e-3d1aa41d5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df)\n",
    "M = len(models)\n",
    "Weights = np.ones((N, M))/M\n",
    "losses = {k:[0] for k in models}\n",
    "lr = 1e-4\n",
    "L = [0]\n",
    "preds = []\n",
    "lr = 1/np.sqrt(N)\n",
    "Linf = 6000\n",
    "lr = np.sqrt(2*np.log(M)/(Linf*N))\n",
    "alg = MWU(lr, M)\n",
    "# alg = MWU(0, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186c1e1e-0132-4940-b67c-309b352cafe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in tqdm(range(N)):\n",
    "    trans = df.iloc[idx]\n",
    "    true_label = trans[\"true\"]\n",
    "    amount = trans[\"Amount\"]\n",
    "    predictions = np.array([trans[m] for m in models])\n",
    "    \n",
    "    model_prediction = alg.predict(predictions)\n",
    "    loss_vector = f_losses(true_label, predictions, alg.w, amount, sogliazza=False)\n",
    "    L.append(loss_vector[-1])\n",
    "    preds.append(model_prediction)\n",
    "    Weights[idx] = alg.w\n",
    "    \n",
    "    for i,m in enumerate(models):\n",
    "        #inst_loss_m = loss(true_label, trans[m], amount)\n",
    "        losses[m].append(loss_vector[i])\n",
    "        \n",
    "    grad = grad_loss(true_label, predictions, amount)\n",
    "    alg.update(grad)\n",
    "    \"\"\"\n",
    "    if idx>N//2 and true_label != model_prediction:\n",
    "        print(loss(true_label, model_prediction, amount))\n",
    "        print(loss(true_label, trans[m], amount))\n",
    "        print(model_prediction, trans[m])\n",
    "        print()\n",
    "    \"\"\"\n",
    "for m in models:\n",
    "    losses[m] = np.cumsum(losses[m])\n",
    "L = np.cumsum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c67bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"majority\"] = df.apply(lambda row: 1 if sum(row[models]) > len(models)/2 else 0, axis=1)\n",
    "loss_majority = []\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    loss_majority.append(single_loss(row[\"true\"], row[\"majority\"], row[\"Amount\"]))\n",
    "\n",
    "loss_majority = np.cumsum(loss_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_matrix = np.array([losses[m] for m in models])\n",
    "mean_loss = loss_matrix.mean(axis=0)\n",
    "print(mean_loss.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46016e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = L[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_loss = mean_loss[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in losses:\n",
    "    losses[k] = losses[k][1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce083ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[\"MWU\"] = L\n",
    "losses[\"MAJORITY\"] = loss_majority\n",
    "losses[\"MEAN\"] = mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200678dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(losses)\n",
    "loss_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df.to_csv(loss_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b233bb0d-3bed-4fe7-9188-7307496d0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT = len(L)\n",
    "#TOT = 50000\n",
    "\n",
    "T = np.arange(TOT)\n",
    "idx = np.arange(1, TOT, TOT//2001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913aa004-64e8-45fd-85b6-1457c0183f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "color_names = ['Purples', 'Blues', \"Reds\", 'Greens', 'Oranges']\n",
    "cmaps = [plt.get_cmap(c) for c in color_names]\n",
    "\n",
    "colors = [cmap(np.linspace(0.3, 1.0, 6)) for cmap in cmaps]\n",
    "colors = [c for cmap in colors for c in cmap]\n",
    "\n",
    "for i,m in enumerate(sorted(models)):\n",
    "    plt.plot(T[idx], losses[m][idx], label=m, color=colors[i])\n",
    "plt.plot(T[idx], L[idx], \"*-\", label=\"MWU\", markevery=100)\n",
    "#plt.ylim(0, 2*10**7)\n",
    "plt.ylabel(\"$L_T$\")\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.grid()\n",
    "plt.savefig(file_name+\"perf.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d45af-7dba-40c3-b29a-22c46cb4c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.stackplot(T[idx], (Weights[idx].T), colors = colors)\n",
    "plt.savefig(file_name+\"weights.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ad5ef-96e2-4af6-9c75-c6ec049fb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+\"Weights.npy\", \"wb\") as f:\n",
    "    np.save(f, Weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7e6847781fc11fada5403783467fe4955bb1980803bb2d7fbfb4738986c9fa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
